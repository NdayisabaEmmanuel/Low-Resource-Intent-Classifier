{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:53.054423Z",
     "iopub.status.busy": "2022-05-08T10:53:53.054126Z",
     "iopub.status.idle": "2022-05-08T10:53:53.060358Z",
     "shell.execute_reply": "2022-05-08T10:53:53.059597Z",
     "shell.execute_reply.started": "2022-05-08T10:53:53.054394Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook first trains a sequence generation model and then use the model to generate sequences \n",
    "for data augmentation for intent classification model.\n",
    "Each generated sequence is then added to dataset as a new utterance.\n",
    "After all that an intent classier is used for classification\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "This notebook can be run from top to bottom\n",
    "It runs a grid search of combinations of speakers and utterrances \n",
    "may take a while. Sometimes up to 4 hours\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:53.131359Z",
     "iopub.status.busy": "2022-05-08T10:53:53.131131Z",
     "iopub.status.idle": "2022-05-08T10:54:02.064862Z",
     "shell.execute_reply": "2022-05-08T10:54:02.06398Z",
     "shell.execute_reply.started": "2022-05-08T10:53:53.131335Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:02.068471Z",
     "iopub.status.busy": "2022-05-08T10:54:02.068247Z",
     "iopub.status.idle": "2022-05-08T10:54:19.728309Z",
     "shell.execute_reply": "2022-05-08T10:54:19.727485Z",
     "shell.execute_reply.started": "2022-05-08T10:54:02.068446Z"
    },
    "id": "9m2fl7X8TrHs",
    "outputId": "ef1e780b-4cfe-4a0e-9fd2-a2d2570279f2"
   },
   "outputs": [],
   "source": [
    "#Download dataset\n",
    "!gdown --fuzzy https://drive.google.com/file/d/1LIrogRWSL-4CifdzciM6vV8V30JArQG6/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:19.729912Z",
     "iopub.status.busy": "2022-05-08T10:54:19.729696Z",
     "iopub.status.idle": "2022-05-08T10:54:21.461903Z",
     "shell.execute_reply": "2022-05-08T10:54:21.460896Z",
     "shell.execute_reply.started": "2022-05-08T10:54:19.729887Z"
    },
    "id": "u2iWhn4bUIYU"
   },
   "outputs": [],
   "source": [
    "!unzip -qn ./phonemes.zip \n",
    "!rm -rf 'phonemes/validation/pp10/spchdatadir/recording1/Untitled.ipynb' #Remove this unwantd file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:21.466105Z",
     "iopub.status.busy": "2022-05-08T10:54:21.465886Z",
     "iopub.status.idle": "2022-05-08T10:54:30.046938Z",
     "shell.execute_reply": "2022-05-08T10:54:30.045978Z",
     "shell.execute_reply.started": "2022-05-08T10:54:21.466078Z"
    },
    "id": "aJbH0QwLTrHu",
    "outputId": "15593906-11fd-47bf-b3f9-c51ab26bc2c7"
   },
   "outputs": [],
   "source": [
    "!pip install torchsummaryX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:30.05027Z",
     "iopub.status.busy": "2022-05-08T10:54:30.049833Z",
     "iopub.status.idle": "2022-05-08T10:54:30.064287Z",
     "shell.execute_reply": "2022-05-08T10:54:30.063578Z",
     "shell.execute_reply.started": "2022-05-08T10:54:30.050232Z"
    },
    "id": "DOc0VqvdTrHv",
    "outputId": "0394642f-34e2-42cd-9454-90de31c08745"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time\n",
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummaryX import summary\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:30.066652Z",
     "iopub.status.busy": "2022-05-08T10:54:30.065701Z",
     "iopub.status.idle": "2022-05-08T10:54:30.080134Z",
     "shell.execute_reply": "2022-05-08T10:54:30.079183Z",
     "shell.execute_reply.started": "2022-05-08T10:54:30.066598Z"
    },
    "id": "Vu6LheJWTrHv"
   },
   "outputs": [],
   "source": [
    "#We use 2 and 4 intents classification for our final report\n",
    "intents_6 = [\"move\", 'turn', 'approach', 'grab', 'point', 'lift']\n",
    "intents_4 = ['approach', 'grab', 'point', 'lift']\n",
    "intents_2 = ['approach', 'lift']\n",
    "intents_3 = ['approach', 'grab', 'point']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:30.081382Z",
     "iopub.status.busy": "2022-05-08T10:54:30.081054Z",
     "iopub.status.idle": "2022-05-08T10:54:32.038085Z",
     "shell.execute_reply": "2022-05-08T10:54:32.037375Z",
     "shell.execute_reply.started": "2022-05-08T10:54:30.081343Z"
    },
    "id": "o4U9QtfcTrHw"
   },
   "outputs": [],
   "source": [
    "X_dir = 'phonemes/train/*/spchdatadir/*/*'\n",
    "X_dir_val = 'phonemes/validation/*/spchdatadir/*/*'\n",
    "X_dir_test = 'phonemes/test/*/spchdatadir/*/*'\n",
    "\n",
    "X_files_train = sorted(glob.glob(X_dir))\n",
    "X_files_val = sorted(glob.glob(X_dir_val))\n",
    "X_files_test = sorted(glob.glob(X_dir_test))\n",
    "files = X_files_train\n",
    "files.extend(X_files_val)\n",
    "files.extend(X_files_test)\n",
    "\n",
    "all_phones = []\n",
    "\n",
    "phones = set()\n",
    "\n",
    "#Get all phonemes occuring in the dataset\n",
    "for x in files:\n",
    "    f = np.load(x)\n",
    "    phones.update(f)\n",
    "    all_phones.extend(f)\n",
    "    \n",
    "PHONEMES = list(phones) #Phoneme vocaburaly\n",
    "vocab = PHONEMES\n",
    "\n",
    "#A utility function to get number of required number of records\n",
    "def records(lis, num):\n",
    "    recs = []\n",
    "    for i in range(0, len(lis), 15):\n",
    "        recs.extend(lis[i:i+num])\n",
    "    return recs\n",
    "\n",
    "#A utility function to pull files depending on the list of intents chosen\n",
    "def intents_func(intents_lis, X_files, Y_files):\n",
    "    xfiles = []\n",
    "    yfiles = []\n",
    "    for i, file in enumerate(Y_files):         \n",
    "        f = open(file) \n",
    "        intent = f.read()   \n",
    "        if intent in intents_lis:\n",
    "            xfiles.append(X_files[i])\n",
    "            yfiles.append(file)\n",
    "\n",
    "    return xfiles, yfiles, intents_lis\n",
    "\n",
    "#A utility function to retrieve speakers required\n",
    "def choose_speakers(speakers_lis, xlis, ylis, n=7):\n",
    "    speakers = random.choices(speakers_lis, k=n)\n",
    "    x_train_files = []\n",
    "    y_train_files = []\n",
    "    for i, file in enumerate(xlis):\n",
    "        dirs = file.split('/')\n",
    "        for speaker in speakers:\n",
    "            if speaker in dirs:\n",
    "                x_train_files.append(file)\n",
    "                y_train_files.append(ylis[i]) \n",
    "    return x_train_files, y_train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:32.039688Z",
     "iopub.status.busy": "2022-05-08T10:54:32.039421Z",
     "iopub.status.idle": "2022-05-08T10:54:32.086351Z",
     "shell.execute_reply": "2022-05-08T10:54:32.085573Z",
     "shell.execute_reply.started": "2022-05-08T10:54:32.039653Z"
    },
    "id": "mYBNFpy1J8Jc",
    "outputId": "0f99af97-0fb8-4a02-bf41-50e7eeecde76"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Phones': all_phones})\n",
    "\n",
    "#Get frequent phonemes\n",
    "most_freq = list(df['Phones'].value_counts()[:10].index)\n",
    "most_freq_idcs = [PHONEMES.index(xx) for xx in most_freq]\n",
    "most_freq_idcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:32.088059Z",
     "iopub.status.busy": "2022-05-08T10:54:32.087805Z",
     "iopub.status.idle": "2022-05-08T10:54:32.092086Z",
     "shell.execute_reply": "2022-05-08T10:54:32.091244Z",
     "shell.execute_reply.started": "2022-05-08T10:54:32.088026Z"
    },
    "id": "YzAT--l8TrHx"
   },
   "outputs": [],
   "source": [
    "speakers = ['pp2', 'pp3', 'pp4', 'pp5', 'pp6', 'pp7', 'pp8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:32.096031Z",
     "iopub.status.busy": "2022-05-08T10:54:32.095552Z",
     "iopub.status.idle": "2022-05-08T10:54:32.126971Z",
     "shell.execute_reply": "2022-05-08T10:54:32.126345Z",
     "shell.execute_reply.started": "2022-05-08T10:54:32.095993Z"
    },
    "id": "K2Q7xNU2TrHy"
   },
   "outputs": [],
   "source": [
    "partition_train= \"train\"\n",
    "partition_validate= \"validation\"\n",
    "\n",
    "X_dir_train = 'phonemes/' + partition_train + '/*/spchdatadir/*/*'\n",
    "X_files_train = sorted(glob.glob(X_dir_train)) #Train files\n",
    "\n",
    "X_dir_val = 'phonemes/' + partition_validate + '/*/spchdatadir/*/*'\n",
    "X_files_val = sorted(glob.glob(X_dir_val))  #Validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:32.128433Z",
     "iopub.status.busy": "2022-05-08T10:54:32.128195Z",
     "iopub.status.idle": "2022-05-08T10:54:33.652773Z",
     "shell.execute_reply": "2022-05-08T10:54:33.651982Z",
     "shell.execute_reply.started": "2022-05-08T10:54:32.128402Z"
    },
    "id": "0XqZRu95TrHz"
   },
   "outputs": [],
   "source": [
    "#Get all utterances and convert them to indices then append to a list\n",
    "#The list contains all utterances\n",
    "dataset = []\n",
    "for path in X_files_train:\n",
    "    X = np.load(path)\n",
    "    \n",
    "    X_indices = [PHONEMES.index(xx) for xx in X]\n",
    "    dataset.append(X_indices)\n",
    "    \n",
    "for path in X_files_val:\n",
    "    X = np.load(path)\n",
    "    X_indices = [PHONEMES.index(xx) for xx in X]\n",
    "    dataset.append(X_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:33.656117Z",
     "iopub.status.busy": "2022-05-08T10:54:33.653992Z",
     "iopub.status.idle": "2022-05-08T10:54:33.665203Z",
     "shell.execute_reply": "2022-05-08T10:54:33.664357Z",
     "shell.execute_reply.started": "2022-05-08T10:54:33.656076Z"
    },
    "id": "eLzjdP4-TrHz"
   },
   "outputs": [],
   "source": [
    "#Dataloader similar to HW4P1\n",
    "class LanguageModelDataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "        TODO: Define data loader logic here\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size, seq_lens=[9, 6], shuffle=True):\n",
    "        # super(dataset).__init__()\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_lens = seq_lens\n",
    "\n",
    "    def __iter__(self):\n",
    "        # concatenate your articles and build in0to batches\n",
    "        dataset = self.dataset\n",
    "        np.random.shuffle(dataset)\n",
    "        concatenated = np.concatenate(dataset)\n",
    "#         concatenated = [torch.tensor(it) for it in concatenated]\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        seq_len = np.random.choice(self.seq_lens, p=[0.95, 0.05])\n",
    "        for i in range(0, len(concatenated), seq_len):\n",
    "            inputs.append(torch.tensor(concatenated[i:i+seq_len], dtype=torch.long))\n",
    "            targets.append(torch.tensor(concatenated[i+1:i+seq_len+1], dtype=torch.long))\n",
    "        inputs = inputs[:-1]\n",
    "        targets = targets[:-1]\n",
    "        for i in range(0, len(inputs), self.batch_size):\n",
    "            yield inputs[i:i+self.batch_size], targets[i:i+self.batch_size]            \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:33.666899Z",
     "iopub.status.busy": "2022-05-08T10:54:33.66648Z",
     "iopub.status.idle": "2022-05-08T10:54:33.677505Z",
     "shell.execute_reply": "2022-05-08T10:54:33.676868Z",
     "shell.execute_reply.started": "2022-05-08T10:54:33.666861Z"
    },
    "id": "ImEt1B3xsPY0"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LockedDropout(nn.Module):\n",
    "    \"\"\" LockedDropout applies the same dropout mask to every time step.\n",
    "\n",
    "    **Thank you** to Sales Force for their initial implementation of :class:`WeightDrop`. Here is\n",
    "    their `License\n",
    "    <https://github.com/salesforce/awd-lstm-lm/blob/master/LICENSE>`__.\n",
    "\n",
    "    Args:\n",
    "        p (float): Probability of an element in the dropout mask to be zeroed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (:class:`torch.FloatTensor` [sequence length, batch size, rnn hidden size]): Input to\n",
    "                apply dropout too.\n",
    "        \"\"\"\n",
    "        if not self.training or not self.p:\n",
    "            return x\n",
    "        x = x.clone()\n",
    "        mask = x.new_empty(1, x.size(1), x.size(2), requires_grad=False).bernoulli_(1 - self.p)\n",
    "        mask = mask.div_(1 - self.p)\n",
    "        mask = mask.expand_as(x)\n",
    "        return x * mask\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'p=' + str(self.p) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:33.679221Z",
     "iopub.status.busy": "2022-05-08T10:54:33.678946Z",
     "iopub.status.idle": "2022-05-08T10:54:33.690749Z",
     "shell.execute_reply": "2022-05-08T10:54:33.689938Z",
     "shell.execute_reply.started": "2022-05-08T10:54:33.679189Z"
    },
    "id": "FP2wc8U2sUCq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "def embedded_dropout(embed, words, dropout=0.2, scale=None):\n",
    "  if dropout:\n",
    "    mask = embed.weight.data.new().resize_((embed.weight.size(0), 1)).bernoulli_(1 - dropout).expand_as(embed.weight) / (1 - dropout)\n",
    "    masked_embed_weight = mask * embed.weight\n",
    "  else:\n",
    "    masked_embed_weight = embed.weight\n",
    "  if scale:\n",
    "    masked_embed_weight = scale.expand_as(masked_embed_weight) * masked_embed_weight\n",
    "\n",
    "  padding_idx = embed.padding_idx\n",
    "  if padding_idx is None:\n",
    "      padding_idx = -1\n",
    "\n",
    "  X = torch.nn.functional.embedding(words, masked_embed_weight,\n",
    "    padding_idx, embed.max_norm, embed.norm_type,\n",
    "    embed.scale_grad_by_freq, embed.sparse\n",
    "  )\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:33.692185Z",
     "iopub.status.busy": "2022-05-08T10:54:33.691858Z",
     "iopub.status.idle": "2022-05-08T10:54:33.7022Z",
     "shell.execute_reply": "2022-05-08T10:54:33.701191Z",
     "shell.execute_reply.started": "2022-05-08T10:54:33.692143Z"
    },
    "id": "fmeIRNmpsYwY"
   },
   "outputs": [],
   "source": [
    "# model for sequene generation\n",
    "#Similar to HW4P1\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "        TODO: Define your model here\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedd_size=256, hidden_size=512, p=0.3):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedd_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedd_size, hidden_size, 3, batch_first=True, dropout=0.4)\n",
    "        self.locked_dropout = LockedDropout(p)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(hidden_size, 1024), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, hidden_size))\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        self.fc.weight = self.embedding.weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = embedded_dropout(self.embedding, x)\n",
    "\n",
    "        embed = self.locked_dropout(embed)\n",
    "\n",
    "        output, out_hid = self.lstm(embed)\n",
    "        output = self.locked_dropout(output)\n",
    "\n",
    "        output = self.fc(output)\n",
    "        output = self.fc2(output)\n",
    "      \n",
    "        return output\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:33.703865Z",
     "iopub.status.busy": "2022-05-08T10:54:33.703262Z",
     "iopub.status.idle": "2022-05-08T10:54:33.717794Z",
     "shell.execute_reply": "2022-05-08T10:54:33.71691Z",
     "shell.execute_reply.started": "2022-05-08T10:54:33.703824Z"
    },
    "id": "SbsGF1dMsaX3"
   },
   "outputs": [],
   "source": [
    "# model trainer\n",
    "\n",
    "class LanguageModelTrainer:\n",
    "    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n",
    "        \"\"\"\n",
    "            Use this class to train your model\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.train_losses = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        # self.optimizer = optim.ASGD(self.model.parameters(), lr= 0.002, t0=50000, weight_decay=1e-4)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.002)\n",
    "        # self.optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "        # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, min_lr=0.0004, patience=3, verbose=False)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
    "            \n",
    "            loss = self.train_batch(inputs, targets)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        \"\"\" \n",
    "            TODO: Define code for training a single batch of inputs\n",
    "        \n",
    "        \"\"\"\n",
    "        inputs = torch.stack(inputs).to(device)\n",
    "        targets = torch.stack(targets).to(device)\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model(inputs)\n",
    "        outputs = torch.transpose(outputs, 2, 1)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:33.731957Z",
     "iopub.status.busy": "2022-05-08T10:54:33.730913Z",
     "iopub.status.idle": "2022-05-08T10:54:33.740094Z",
     "shell.execute_reply": "2022-05-08T10:54:33.739457Z",
     "shell.execute_reply.started": "2022-05-08T10:54:33.731925Z"
    },
    "id": "WWf1LEqDskFe"
   },
   "outputs": [],
   "source": [
    "# TODO: define other hyperparameters here\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:33.741792Z",
     "iopub.status.busy": "2022-05-08T10:54:33.741274Z",
     "iopub.status.idle": "2022-05-08T10:54:33.917465Z",
     "shell.execute_reply": "2022-05-08T10:54:33.916677Z",
     "shell.execute_reply.started": "2022-05-08T10:54:33.741764Z"
    },
    "id": "-tVomWG3sqVN",
    "outputId": "2beb6c70-b0f3-41e4-ea00-2e85ec9aa264"
   },
   "outputs": [],
   "source": [
    "run_id = str(int(time.time()))\n",
    "gen_model = LanguageModel(len(vocab)).cuda()\n",
    "loader = LanguageModelDataLoader(dataset=dataset, batch_size=BATCH_SIZE, seq_lens=[40, 60], shuffle=True)\n",
    "trainer = LanguageModelTrainer(model=gen_model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:54:33.952711Z",
     "iopub.status.busy": "2022-05-08T10:54:33.95197Z",
     "iopub.status.idle": "2022-05-08T10:56:55.580963Z",
     "shell.execute_reply": "2022-05-08T10:56:55.580202Z",
     "shell.execute_reply.started": "2022-05-08T10:54:33.952667Z"
    },
    "id": "rVFQA1isssp8",
    "outputId": "5fc939b3-0ddc-464c-b029-30a9a693b169"
   },
   "outputs": [],
   "source": [
    "\n",
    "best_nll = 1e30 \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utghaf1ATrH1"
   },
   "source": [
    "\"\"\"The purpose of the project is to convert audio recordings into phonemes and then classify the phonemes into intents.\n",
    "Each sequence of phonemes is mapped to one of 6 intents. The model should be able to read phoneme sequence\n",
    "and output an intent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:56:55.584242Z",
     "iopub.status.busy": "2022-05-08T10:56:55.584013Z",
     "iopub.status.idle": "2022-05-08T10:56:55.602662Z",
     "shell.execute_reply": "2022-05-08T10:56:55.601795Z",
     "shell.execute_reply.started": "2022-05-08T10:56:55.584209Z"
    },
    "id": "hDyZ0eoWWq0B"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The dataset class reads sequnce of phonemes and a correspong intent.\n",
    "The phonemes are mapped into indices using the above PHONEMES list\n",
    "\"\"\"\n",
    "class LibriSamples(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, recs, intents_lst, speakers_num, partition= \"train\"): \n",
    "        self.X_dir = 'phonemes/' + partition + '/*/spchdatadir/*/*'\n",
    "        self.Y_dir = 'phonemes/' + partition + '/*/framedir/*/*'\n",
    "        \n",
    "        self.X_files = sorted(glob.glob(self.X_dir)) \n",
    "        self.Y_files = sorted(glob.glob(self.Y_dir))             \n",
    "        \n",
    "        X_files = records(self.X_files, recs)\n",
    "        Y_files = records(self.Y_files, recs)\n",
    "        \n",
    "        x_files, y_files, self.intents = intents_func(intents_lst, X_files, Y_files)\n",
    "        \n",
    "        if partition == 'train':\n",
    "            self.X_files, self.Y_files = choose_speakers(speakers, x_files, y_files, speakers_num)\n",
    "        else:\n",
    "            self.X_files, self.Y_files = x_files, y_files\n",
    "                \n",
    "        self.PHONEMES = PHONEMES\n",
    "        assert(len(self.X_files) == len(self.Y_files))\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        aug_inputs = []\n",
    "        aug_targets = []\n",
    "#         print(partition)\n",
    "\n",
    "        for ind in range(len(self.X_files)):\n",
    "            X_path = self.X_files[ind] \n",
    "            Y_path = self.Y_files[ind] \n",
    "            X = np.load(X_path)\n",
    "            X_indices = [PHONEMES.index(xx) for xx in X]\n",
    "            f = open(Y_path) \n",
    "            r = f.read() \n",
    "            Y_index = self.intents.index(r) \n",
    "\n",
    "            ln = len(X_indices)\n",
    "            temp = X_indices.copy()\n",
    "\n",
    "            probs = [0.25, 0.2, 0.15, 0.15, 0.1, 0.08, 0.02, 0.02, 0.02, 0.01]\n",
    "\n",
    "            #Generate new sequence from utterance in dataset\n",
    "            for i in range(1, ln, 1):\n",
    "                ph = X_indices[:i]\n",
    "                ph = torch.tensor([ph]).to(device)\n",
    "\n",
    "                preds = gen_model(ph)\n",
    "                preds = preds[:, -1, :]\n",
    "                indices = torch.argmax(preds,  axis=1)\n",
    "\n",
    "                temp[i] = indices[0].item()\n",
    "\n",
    "            # print(ch)\n",
    "#             if not ch:\n",
    "#               for i in range(ln):\n",
    "#                     freq_idx = np.random.choice(most_freq_idcs, p=probs)\n",
    "#                     temp[i] = freq_idx\n",
    "                    \n",
    "            # print(\"X indices\", X_indices)\n",
    "            # print(\"Temp\", temp)\n",
    "\n",
    "            if partition ==  'train':\n",
    "\n",
    "                self.inputs.append(X_indices)\n",
    "                self.targets.append(Y_index)\n",
    "                aug_inputs.append(temp) #Add new utterance to dataset\n",
    "                aug_targets.append(Y_index)\n",
    "            else:\n",
    "                self.inputs.append(X_indices)\n",
    "                self.targets.append(Y_index)\n",
    "                \n",
    "            f.close()\n",
    "\n",
    "        self.inputs.extend(aug_inputs)\n",
    "        self.targets.extend(aug_targets)\n",
    "        assert(len(self.inputs) == len(self.targets))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_files)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "\n",
    "        return self.inputs[ind], self.targets[ind]\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "\n",
    "        batch_x = [torch.tensor(x) for x,y in batch] \n",
    "        batch_y = [torch.tensor(y) for x,y in batch]\n",
    "        batch_x_pad = pad_sequence(batch_x, batch_first=True, padding_value=0) #Utterances have variable length\n",
    "        lengths_x = [len(x) for x,y in batch] #Store lenghths of all utterances\n",
    "\n",
    "        return batch_x_pad, torch.tensor(batch_y), torch.tensor(lengths_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:56:55.604409Z",
     "iopub.status.busy": "2022-05-08T10:56:55.603971Z",
     "iopub.status.idle": "2022-05-08T10:56:55.61781Z",
     "shell.execute_reply": "2022-05-08T10:56:55.616992Z",
     "shell.execute_reply.started": "2022-05-08T10:56:55.604368Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "def data_prep(recs, intent_lst, speakers_num):\n",
    "    #Load dataloaders with specified records, intents list, and number of speakers\n",
    "    train_data = LibriSamples(recs, intent_lst, speakers_num, 'train')\n",
    "    val_data = LibriSamples(recs, intent_lst, speakers_num, 'validation')\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True, collate_fn=train_data.collate_fn)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size, shuffle=False, collate_fn=val_data.collate_fn)\n",
    "\n",
    "    label_sizes = 0 \n",
    "    \n",
    "    if len(intent_lst) == 2:\n",
    "        label_sizes = 2\n",
    "        \n",
    "    elif len(intent_lst) == 3:\n",
    "        label_sizes = 3\n",
    "        \n",
    "    elif len(intent_lst) == 4:\n",
    "        label_sizes = 4\n",
    "        \n",
    "    elif len(intent_lst) == 6:\n",
    "        label_sizes = 6\n",
    "    \n",
    "    for data in val_loader:\n",
    "        x, y, lx = data \n",
    "        break\n",
    "\n",
    "    return train_loader, val_loader, x, y, lx, label_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:56:55.619474Z",
     "iopub.status.busy": "2022-05-08T10:56:55.619153Z",
     "iopub.status.idle": "2022-05-08T10:56:55.667981Z",
     "shell.execute_reply": "2022-05-08T10:56:55.66725Z",
     "shell.execute_reply.started": "2022-05-08T10:56:55.619441Z"
    },
    "id": "LeZCZlKnTrH4",
    "outputId": "8767f546-3900-47f1-86ff-c52fc9909146"
   },
   "outputs": [],
   "source": [
    "#Classifier architecture\n",
    "class ICASSP2CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size=128, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=31):\n",
    "        super().__init__()\n",
    "        self.n_layers = num_lstm_layers \n",
    "        self.hidden = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(2 * embed_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = 2 * embed_size, \n",
    "                            hidden_size = hidden_size, \n",
    "                            num_layers = num_lstm_layers, \n",
    "                            bidirectional = bidirectional\n",
    "                            )\n",
    "\n",
    "        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n",
    "                                out_features = label_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "\n",
    "        input = self.embed(x)\n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input)], dim=1)\n",
    "\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n",
    "            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n",
    "        else:\n",
    "            h_n = hn[-1]\n",
    "        \n",
    "        logits = self.linear(h_n)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "model = ICASSP2CNN(len(PHONEMES), label_size=4).cuda() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:56:55.669627Z",
     "iopub.status.busy": "2022-05-08T10:56:55.669348Z",
     "iopub.status.idle": "2022-05-08T10:56:55.674872Z",
     "shell.execute_reply": "2022-05-08T10:56:55.674008Z",
     "shell.execute_reply.started": "2022-05-08T10:56:55.669593Z"
    },
    "id": "zVg5QTfUTrH5"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.999, min_lr=0.0005, patience=5, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:56:55.676935Z",
     "iopub.status.busy": "2022-05-08T10:56:55.676526Z",
     "iopub.status.idle": "2022-05-08T10:56:55.694856Z",
     "shell.execute_reply": "2022-05-08T10:56:55.694015Z",
     "shell.execute_reply.started": "2022-05-08T10:56:55.676899Z"
    },
    "id": "ZdJ3FuEBTrH6"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader,label_sizes, intent=None, k=None, s=None, p=None):  # todo: separation of train & validation. Which data should we train on?\n",
    "    torch.cuda.empty_cache()\n",
    "    model = ICASSP2CNN(len(PHONEMES), label_size=label_sizes).cuda() \n",
    "    criterion = torch.nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.999, min_lr=0.0005, patience=5, verbose=False)\n",
    "    last_improvement = 0\n",
    "    best_acc = 0\n",
    "    epochs = 1000\n",
    "    patience_epochs = 400\n",
    "    epoch_bar = tqdm(total=epochs, dynamic_ncols=True, leave=True, position=0, desc='Train')\n",
    "\n",
    "    for epoch in list(range(epochs)):\n",
    "        model.train()\n",
    "        num_correct = 0\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, _data in enumerate(train_loader):\n",
    "\n",
    "            x, y, input_lengths = _data\n",
    "            data = x.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            with torch.cuda.amp.autocast():     \n",
    "                outputs = model(x, input_lengths)     \n",
    "                loss = criterion(outputs, y)\n",
    "            \n",
    "            num_correct += int((torch.argmax(outputs,  axis=1) == y).sum())\n",
    "            total_loss += float(loss)\n",
    "            \n",
    "            ls = torch.argmax(outputs, axis=1)\n",
    "            scaler.scale(loss).backward() \n",
    "\n",
    "            scaler.step(optimizer) \n",
    "\n",
    "            scaler.update() \n",
    "\n",
    "        model.eval()\n",
    "        num_correct2 = 0\n",
    "        for i, _data in enumerate(val_loader):\n",
    "            x, y, input_lengths = _data\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(x, input_lengths)\n",
    "\n",
    "            num_correct2 += int((torch.argmax(outputs,  axis=1) == y).sum())\n",
    "\n",
    "        last_improvement+=1\n",
    "\n",
    "        validation_score = 100 * num_correct2 / ((len(val_loader) * batch_size))\n",
    "        if best_acc < validation_score:\n",
    "            best_acc = validation_score\n",
    "            last_improvement = 0\n",
    "\n",
    "        if last_improvement == patience_epochs:\n",
    "          # print(f\"Breaking since model refused to learn for {patience_epochs} patience epochs\")\n",
    "          break\n",
    "        m = \"i={} k={} s={} p={} - Epoch {}/{}: Train Acc {:.04f}%, Train Loss {:.04f}, Learning Rate {:.04f} CurrAcc: {:.2f} BestAcc: {:.2f} currPatience: {}\".format(\n",
    "            intent, k, s, p, int(epoch) + 1, epochs,\n",
    "            100 * num_correct / (len(train_loader) * batch_size),\n",
    "            float(total_loss / len(train_loader)),\n",
    "            float(optimizer.param_groups[0]['lr']), validation_score, best_acc, patience_epochs-last_improvement )\n",
    "        epoch_bar.set_description(m)\n",
    "        epoch_bar.update()\n",
    "    epoch_bar.close()\n",
    "\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:56:55.696487Z",
     "iopub.status.busy": "2022-05-08T10:56:55.695891Z"
    },
    "id": "DK7vMyJsxISz",
    "outputId": "8260e90c-967d-4e3c-9016-7406899532a5"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'intents': zip([\"Two\"],[intents_2]),\n",
    "    'speakers': range(1,8),\n",
    "    'recordings': range(1,8)\n",
    "}\n",
    "\n",
    "intent_scores = {}\n",
    "\n",
    "#Loop that runs grid search \n",
    "for name, intent in params['intents']:\n",
    "    k_scores = {}\n",
    "    for k in params['recordings']:\n",
    "        s_scores = {}\n",
    "        for s in params['speakers']:\n",
    "            train_loader, val_loader, x, y, lx, label_sizes = data_prep(recs=k, intent_lst=intent, speakers_num=s)\n",
    "            val_score = train(train_loader, val_loader, label_sizes, intent=name, k=k, s=s, p=len(PHONEMES))\n",
    "#             print(k,s)\n",
    "            s_scores.update({s: val_score})\n",
    "        k_scores.update({k: s_scores})\n",
    "    intent_scores.update({name: k_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv_xWQJoTrH7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Generate .csv file of grid search results\n",
    "dfs = []\n",
    "for k, v in intent_scores.items():\n",
    "    dfs.append((k, pd.DataFrame(v)))\n",
    "# for i in df:\n",
    "for item in dfs:\n",
    "    item[1].to_csv(f\"{item[0]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
